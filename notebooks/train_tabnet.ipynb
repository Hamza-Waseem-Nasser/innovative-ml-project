{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25416d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import torch\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3be9dfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded transactions: (779495, 10)\n"
     ]
    }
   ],
   "source": [
    "# 1) Load the cleaned transactions\n",
    "df = pd.read_csv(\"../data/transactions_clean.csv\", parse_dates=[\"InvoiceDate\"])\n",
    "print(\"Loaded transactions:\", df.shape)\n",
    "\n",
    "# 2) Feature Engineering\n",
    "# ──────────────────────\n",
    "# Extract time features\n",
    "df[\"hour\"] = df[\"InvoiceDate\"].dt.hour\n",
    "df[\"day_of_week\"] = df[\"InvoiceDate\"].dt.dayofweek\n",
    "df[\"month\"] = df[\"InvoiceDate\"].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "add15151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 779495 entries, 0 to 779494\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   Invoice      779495 non-null  int64         \n",
      " 1   StockCode    779495 non-null  object        \n",
      " 2   Description  779495 non-null  object        \n",
      " 3   Quantity     779495 non-null  int64         \n",
      " 4   InvoiceDate  779495 non-null  datetime64[ns]\n",
      " 5   Price        779495 non-null  float64       \n",
      " 6   Customer ID  779495 non-null  float64       \n",
      " 7   Country      779495 non-null  object        \n",
      " 8   TotalPrice   779495 non-null  float64       \n",
      " 9   Month        779495 non-null  object        \n",
      " 10  hour         779495 non-null  int32         \n",
      " 11  day_of_week  779495 non-null  int32         \n",
      " 12  month        779495 non-null  int32         \n",
      "dtypes: datetime64[ns](1), float64(3), int32(3), int64(2), object(4)\n",
      "memory usage: 68.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bcc8e90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "target = \"TotalPrice\"\n",
    "categorical_cols = [\"StockCode\", \"Country\"]\n",
    "numerical_cols   = [\"Quantity\", \"Price\", \"hour\", \"day_of_week\", \"month\"]\n",
    "features = categorical_cols + numerical_cols\n",
    "\n",
    "# 3) Encode categoricals\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "    joblib.dump(le, f\"../models/enc_{col}.pkl\")  # save encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16f0ac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Prepare data arrays\n",
    "X = df[features].values\n",
    "y = df[target].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "23ba6660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (623596, 7) Test size: (155899, 7)\n"
     ]
    }
   ],
   "source": [
    "# 5) Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(\"Train size:\", X_train.shape, \"Test size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e84bc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/scaler_num.pkl']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6) Scale numerical features\n",
    "#    We scale only the numerical part of X\n",
    "num_start = len(categorical_cols)\n",
    "scaler = StandardScaler()\n",
    "X_train[:, num_start:] = scaler.fit_transform(X_train[:, num_start:])\n",
    "X_test[:, num_start:]  = scaler.transform(X_test[:, num_start:])\n",
    "joblib.dump(scaler, \"../models/scaler_num.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3515cec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\Innovative-ml-project\\NEW-ML-PROJECT\\.venv\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "c:\\Users\\hp\\Innovative-ml-project\\NEW-ML-PROJECT\\.venv\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.31245 |  0:00:41s\n",
      "epoch 1  | loss: 1.39254 |  0:01:20s\n",
      "Stop training because you reached max_epochs = 2 with best_epoch = 1 and best_loss = 1.39254\n",
      "epoch 1  | loss: 1.39254 |  0:01:20s\n",
      "Stop training because you reached max_epochs = 2 with best_epoch = 1 and best_loss = 1.39254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\Innovative-ml-project\\NEW-ML-PROJECT\\.venv\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model at ../models/tabnet_pretrainer.zip\n",
      "✅ Pretraining complete.\n"
     ]
    }
   ],
   "source": [
    "# 7) Self‑Supervised Pretraining\n",
    "# ────────────────────────────────\n",
    "from pytorch_tabnet.callbacks import EarlyStopping\n",
    "\n",
    "pretrainer = TabNetPretrainer(\n",
    "    input_dim=X_train.shape[1],\n",
    "    mask_type='entmax'  # sparsity in masks\n",
    ")\n",
    "# define callbacks\n",
    "es = EarlyStopping(\n",
    "    patience=20,\n",
    "    early_stopping_metric=\"loss\",  # Metric to monitor\n",
    "    is_maximize=False              # Set to False for minimizing loss\n",
    ")\n",
    "\n",
    "# fit with callbacks and verbose logging\n",
    "pretrainer.fit(\n",
    "    X_train,\n",
    "    max_epochs=2,\n",
    "    batch_size=1024,\n",
    "    virtual_batch_size=128,\n",
    "    pretraining_ratio=0.8,\n",
    "    num_workers=3,\n",
    "    drop_last=False,\n",
    "    callbacks=[es]\n",
    "    \n",
    ")\n",
    "\n",
    "pretrainer.save_model(\"../models/tabnet_pretrainer\")\n",
    "print(\"✅ Pretraining complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "964fd047",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\Innovative-ml-project\\NEW-ML-PROJECT\\.venv\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "# 8) Fine‑Tuning as Regressor\n",
    "# ────────────────────────────\n",
    "regressor = TabNetRegressor(\n",
    "    input_dim=X_train.shape[1],\n",
    "    output_dim=1,\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params={\"lr\":1e-3, \"weight_decay\":1e-4},\n",
    "    scheduler_params={\"step_size\":50, \"gamma\":0.9},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR\n",
    ")\n",
    "\n",
    "# load pretrained encoder weights\n",
    "# Instead of regressor.load_weights_from_unsupervised(pretrainer)\n",
    "# use the following:\n",
    "regressor._set_network() # Initialize the network attribute\n",
    "regressor.load_weights_from_unsupervised(pretrainer) # Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7c68689d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 53419.30011| test_mse: 35898.09669|  0:00:30s\n",
      "epoch 1  | loss: 52088.24793| test_mse: 21379.15374|  0:00:59s\n",
      "Stop training because you reached max_epochs = 2 with best_epoch = 1 and best_test_mse = 21379.15374\n",
      "epoch 1  | loss: 52088.24793| test_mse: 21379.15374|  0:00:59s\n",
      "Stop training because you reached max_epochs = 2 with best_epoch = 1 and best_test_mse = 21379.15374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\Innovative-ml-project\\NEW-ML-PROJECT\\.venv\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# fit on train, evaluate on test\n",
    "regressor.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_name=['test'],\n",
    "    max_epochs=2,\n",
    "    patience=30,\n",
    "    batch_size=1024,\n",
    "    virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "327df0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model at ../models/tabnet_regressor.zip\n",
      "✅ Fine‑tuning complete. Model saved to models/tabnet_regressor.zip\n"
     ]
    }
   ],
   "source": [
    "# Save the fine‑tuned model\n",
    "regressor.save_model(\"../models/tabnet_regressor\")\n",
    "print(\"✅ Fine‑tuning complete. Model saved to models/tabnet_regressor.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d7dbaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
